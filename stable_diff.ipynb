{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Stable Diffusion**\n",
    "- deepface to crop only to head\n",
    "- Duplicate number of heads\n",
    "- resize input images to 1024 1024\n",
    "- Add tensorboard? Track live traning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Set up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/bmaltais/kohya_ss.git /home/datascience/kohya_ss\n",
    "# !mkdir -p /home/datascience/stable-diffusion-xl-base-1.0 && wget -O /home/datascience/stable-diffusion-xl-base-1.0/sd_xl_base_1.0.safetensors https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors\n",
    "\n",
    "# !bash /home/datascience/kohya_ss/setup.sh\n",
    "# !source /home/datascience/kohya_ss/venv/bin/activate\n",
    "#!pip install deepspeed accelerate config default safetensors transformers diffusers einops toml torchvision opencv-python-headless voluptuous xformers deepface open_clip_torch\n",
    "# !pip install mediapipe\n",
    "\n",
    "# !mkdir -p /home/datascience/sks/img/1_sks\\ person\n",
    "# !mkdir -p /home/datascience/sks/reg\n",
    "# !mkdir -p /home/datascience/sks/model\n",
    "# !mkdir -p /home/datascience/sks/log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train Stable Diffusion - SD XL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove output if so\n",
    "!rm -r /home/datascience/sks/output\n",
    "\n",
    "!bash /home/datascience/kohya_ss/setup.sh\n",
    "!source /home/datascience/kohya_ss/venv/bin/activate\n",
    "\n",
    "!accelerate launch  /home/datascience/kohya_ss/sdxl_train_network.py \\\n",
    "  --enable_bucket \\\n",
    "  --min_bucket_reso=256 \\\n",
    "  --max_bucket_reso=2048 \\\n",
    "  --pretrained_model_name_or_path=\"/home/datascience/stable-diffusion-xl-base-1.0/sd_xl_base_1.0.safetensors\" \\\n",
    "  --train_data_dir=\"/home/datascience/sks/img\" \\\n",
    "  --resolution=\"1024,1024\" \\\n",
    "  --output_dir=\"/home/datascience/sks/output\" \\\n",
    "  --network_alpha=\"1\" \\\n",
    "  --save_model_as=safetensors \\\n",
    "  --network_module=networks.lora \\\n",
    "  --text_encoder_lr=0.0004 \\\n",
    "  --unet_lr=0.0004 \\\n",
    "  --network_dim=256 \\\n",
    "  --output_name=\"sks\" \\\n",
    "  --lr_scheduler_num_cycles=\"10\" \\\n",
    "  --no_half_vae --learning_rate=\"0.0004\" \\\n",
    "  --lr_scheduler=\"cosine\" \\\n",
    "  --train_batch_size=\"1\" \\\n",
    "  --max_train_steps=\"800\" \\\n",
    "  --mixed_precision=\"fp16\" \\\n",
    "  --save_precision=\"fp16\" \\\n",
    "  --optimizer_type=\"adafactor\" \\\n",
    "  --cache_latents \\\n",
    "  --cache_latents_to_disk \\\n",
    "  --gradient_checkpointing \\\n",
    "  --optimizer_args scale_parameter=False relative_step=False warmup_init=False \\\n",
    "  --max_data_loader_n_workers=\"0\" \\\n",
    "  --bucket_reso_steps=64 \\\n",
    "  --xformers \\\n",
    "  --bucket_no_upscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SD XL Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some documentation: https://github.com/huggingface/diffusers/pull/4287 and https://huggingface.co/docs/diffusers/main/en/training/lora#supporting-a1111-themed-lora-checkpoints-from-diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /home/datascience/kohya_ss/sdxl_minimal_inference.py --ckpt_path /home/datascience/stable-diffusion-xl-base-1.0/sd_xl_base_1.0.safetensors --output_dir=. --lora_weights /home/datascience/sks/output/sks.safetensors --prompt \"ultra realistic illustration, ((sks man)) in a red bull racing formula 1 suit intricate, elegant, no helmet, highly detailed, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by artgerm and greg rutkowski and alphonse mucha\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **OCI Data Science - Jobs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy folder/files into job artifacts\n",
    "# !cp -R /home/datascience/kohya_ss /home/datascience/job_artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Publish Conda**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.st define bucket and namespace where to store  (conda_environment_yolov5 = bucket name, frqap2zhtzbe = namespace)\n",
    "!odsc conda init -b West_BP -n frqap2zhtzbe -a resource_principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!odsc conda publish -s pytorch20_p39_gpu_v1 --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Create a Job**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ads.common.oci_logging import OCILogGroup, OCILog\n",
    "from ads.jobs import Job, DataScienceJob, PythonRuntime\n",
    "from datetime import datetime, timedelta\n",
    "from ads import set_auth\n",
    "\n",
    "#authentication\n",
    "from ads import set_auth\n",
    "set_auth(auth='resource_principal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "kind: job\n",
       "spec:\n",
       "  id: ocid1.datasciencejob.oc1.eu-frankfurt-1.amaaaaaangencdyamddgmkbvwn5aazhufilhbp2v2mp6o6mn5wsg35tws3xa\n",
       "  infrastructure:\n",
       "    kind: infrastructure\n",
       "    spec:\n",
       "      blockStorageSize: 1000\n",
       "      compartmentId: ocid1.compartment.oc1..aaaaaaaae3n6r6hrjipbap2hojicrsvkzatrtlwvsyrpyjd7wjnw4za3m75q\n",
       "      displayName: stable_dff_v1\n",
       "      jobInfrastructureType: ME_STANDALONE\n",
       "      jobType: DEFAULT\n",
       "      logGroupId: ocid1.loggroup.oc1.eu-frankfurt-1.amaaaaaangencdyajxalcuggjaug57r3ugare7olsk44ts2shyv7azqbxf4q\n",
       "      projectId: ocid1.datascienceproject.oc1.eu-frankfurt-1.amaaaaaangencdyaik5ssdqk4as2bhldxprh7vnqpk7yycsm7vymd344cgua\n",
       "      shapeName: VM.GPU.A10.1\n",
       "    type: dataScienceJob\n",
       "  name: stable_dff_v1\n",
       "  runtime:\n",
       "    kind: runtime\n",
       "    spec:\n",
       "      conda:\n",
       "        type: published\n",
       "        uri: oci://West_BP@frqap2zhtzbe/conda_environments/gpu/PyTorch 2.0 for GPU\n",
       "          on Python 3.9/1.0/pytorch20_p39_gpu_v1\n",
       "      entrypoint: stable_main.py\n",
       "      env:\n",
       "      - name: full_input_folder\n",
       "        value: oci://West_BP@frqap2zhtzbe/stable_diffusion/input_folder/\n",
       "      outputDir: ./inference_output\n",
       "      outputUri: oci://West_BP@frqap2zhtzbe/stable_diffusion/output_folder/\n",
       "      scriptPathURI: /home/datascience/job_artifact/\n",
       "      workingDir: job_artifact\n",
       "    type: python"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the below script creates an OCI Data Science - Job\n",
    "job = (\n",
    "    Job(name=\"stable_dff_v1\")\n",
    "    .with_infrastructure(\n",
    "        DataScienceJob()\n",
    "        # Configure logging for getting the job run outputs.\n",
    "        .with_log_group_id(\"ocid1.loggroup.oc1.eu-frankfurt-1.amaaaaaangencdyajxalcuggjaug57r3ugare7olsk44ts2shyv7azqbxf4q\")\n",
    "        .with_shape_name(\"VM.GPU.A10.1\")\n",
    "        #.with_shape_config_details(memory_in_gbs=16, ocpus=5)\n",
    "        .with_block_storage_size(1000)\n",
    "    )\n",
    "    .with_runtime(\n",
    "        PythonRuntime()\n",
    "        .with_custom_conda(\"oci://West_BP@frqap2zhtzbe/conda_environments/gpu/PyTorch 2.0 for GPU on Python 3.9/1.0/pytorch20_p39_gpu_v1\")\n",
    "        .with_source(\"/home/datascience/job_artifact/\")  \n",
    "        .with_entrypoint(\"stable_main.py\")  \n",
    "        .with_working_dir(\"job_artifact\")\n",
    "        .with_environment_variable(full_input_folder=\"oci://West_BP@frqap2zhtzbe/stable_diffusion/input_folder/\")\n",
    "        .with_output(\"./inference_output\", \"oci://West_BP@frqap2zhtzbe/stable_diffusion/output_folder/\")  #copy output in inference_output to output_folder bucket\n",
    "    )\n",
    ")\n",
    "\n",
    "job.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job OCID: ocid1.datasciencejob.oc1.eu-frankfurt-1.amaaaaaangencdyamddgmkbvwn5aazhufilhbp2v2mp6o6mn5wsg35tws3xa\n",
      "Job Run OCID: ocid1.datasciencejobrun.oc1.eu-frankfurt-1.amaaaaaangencdyafo7ajs5hss45nu5gbky6s2zvigo5vmqvrktj4t6a6tbq\n",
      "2023-08-08 18:08:00 - Job Run ACCEPTED\n",
      "2023-08-08 18:08:13 - Job Run ACCEPTED, Infrastructure provisioning.\n",
      "2023-08-08 18:09:13 - Job Run ACCEPTED, Infrastructure provisioned.\n",
      "2023-08-08 18:09:48 - Job Run ACCEPTED, Job run bootstrap starting.\n",
      "2023-08-08 18:13:35 - Job Run ACCEPTED, Job run bootstrap complete. Artifact execution starting.\n",
      "2023-08-08 18:13:45 - Job Run IN_PROGRESS, Job run artifact execution in progress.\n",
      "2023-08-08 18:13:35 - Full input folder used is oci://West_BP@frqap2zhtzbe/stable_diffusion/input_folder/\n",
      "2023-08-08 18:13:35 - --2023-08-08 18:13:35--  https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors\n",
      "2023-08-08 18:13:35 - Resolving huggingface.co (huggingface.co)... 143.204.215.22, 143.204.215.116, 143.204.215.87, ...\n",
      "2023-08-08 18:13:35 - Connecting to huggingface.co (huggingface.co)|143.204.215.22|:443... connected.\n",
      "2023-08-08 18:13:35 - --2023-08-08 18:13:35--  https://cdn-lfs.huggingface.co/repos/7f/2f/7f2fe2e27137549cd28e570e5bac269b49ebcf1e0e47279c7a941ebe5c948e02/31e35c80fc4829d14f90153f4c74cd59c90b779f6afe05a74cd6120b893f7e5b?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sd_xl_base_1.0.safetensors%3B+filename%3D%22sd_xl_base_1.0.safetensors%22%3B&Expires=1691776867&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5MTc3Njg2N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy83Zi8yZi83ZjJmZTJlMjcxMzc1NDljZDI4ZTU3MGU1YmFjMjY5YjQ5ZWJjZjFlMGU0NzI3OWM3YTk0MWViZTVjOTQ4ZTAyLzMxZTM1YzgwZmM0ODI5ZDE0ZjkwMTUzZjRjNzRjZDU5YzkwYjc3OWY2YWZlMDVhNzRjZDYxMjBiODkzZjdlNWI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=BWGvEaTdUAtvjZ45FgvJvNXzrppeTImD78F3PmW1c6xEltDmS6yDEyEAm8qB0qc2Uas%7E%7Eh%7EiClNxQDdiCqGHd04tzgYvHgzVnlENLJ0wcKLHasEBQ90Ybce8eyau4N59N%7Eb98MwIGsI5wlsgy2uTMUMMb5y3jjmY1pam5asLX--MsDFegTFnORJCvx2jBpGxiEpNQ%7EByK7Mqy7mUKRryOb2prHkGPO%7EnjlizTbMmJwEZTjq1lgJYrSbKf5wtkBqMhCrSt8Bz6DkWsHyxC-JQntyYo5tBUmmBJc19HaIwwBOj6EwsJXVaJW7Z21bpW%7E9seS4Yev2MEkq1pIVe0bMnvw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "2023-08-08 18:13:35 - Location: https://cdn-lfs.huggingface.co/repos/7f/2f/7f2fe2e27137549cd28e570e5bac269b49ebcf1e0e47279c7a941ebe5c948e02/31e35c80fc4829d14f90153f4c74cd59c90b779f6afe05a74cd6120b893f7e5b?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27sd_xl_base_1.0.safetensors%3B+filename%3D%22sd_xl_base_1.0.safetensors%22%3B&Expires=1691776867&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5MTc3Njg2N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy83Zi8yZi83ZjJmZTJlMjcxMzc1NDljZDI4ZTU3MGU1YmFjMjY5YjQ5ZWJjZjFlMGU0NzI3OWM3YTk0MWViZTVjOTQ4ZTAyLzMxZTM1YzgwZmM0ODI5ZDE0ZjkwMTUzZjRjNzRjZDU5YzkwYjc3OWY2YWZlMDVhNzRjZDYxMjBiODkzZjdlNWI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=BWGvEaTdUAtvjZ45FgvJvNXzrppeTImD78F3PmW1c6xEltDmS6yDEyEAm8qB0qc2Uas%7E%7Eh%7EiClNxQDdiCqGHd04tzgYvHgzVnlENLJ0wcKLHasEBQ90Ybce8eyau4N59N%7Eb98MwIGsI5wlsgy2uTMUMMb5y3jjmY1pam5asLX--MsDFegTFnORJCvx2jBpGxiEpNQ%7EByK7Mqy7mUKRryOb2prHkGPO%7EnjlizTbMmJwEZTjq1lgJYrSbKf5wtkBqMhCrSt8Bz6DkWsHyxC-JQntyYo5tBUmmBJc19HaIwwBOj6EwsJXVaJW7Z21bpW%7E9seS4Yev2MEkq1pIVe0bMnvw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "2023-08-08 18:13:35 - HTTP request sent, awaiting response... 302 Found\n",
      "2023-08-08 18:13:35 - Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.63.36, 18.154.63.6, 18.154.63.61, ...\n",
      "2023-08-08 18:13:35 - Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.63.36|:443... connected.\n",
      "2023-08-08 18:13:35 - \n",
      "2023-08-08 18:13:35 - Saving to: ‘stable-diffusion-xl-base-1.0/sd_xl_base_1.0.safetensors’\n",
      "2023-08-08 18:13:35 - Length: 6938078334 (6.5G) [binary/octet-stream]\n",
      "2023-08-08 18:13:35 - HTTP request sent, awaiting response... 200 OK\n",
      "94% [==================================>  ] 6,573,579,976  245MB/s  eta 2s  ...\n",
      "2023-08-08 18:14:01 - \n",
      "2023-08-08 18:14:01 - 2023-08-08 18:14:01 (252 MB/s) - ‘stable-diffusion-xl-base-1.0/sd_xl_base_1.0.safetensors’ saved [6938078334/6938078334]\n",
      "2023-08-08 18:14:01 - \n",
      "2023-08-08 18:14:01 - Skipping git operations.\n",
      "2023-08-08 18:14:01 - Switching to virtual Python environment.\n",
      "2023-08-08 18:14:02 - \u001b[2;36m                \u001b[0m         minutes as it downloads files.                         \n",
      "2023-08-08 18:14:02 - \u001b[2;36m18:14:02-058683\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing python dependencies. This could take a few  \n",
      "2023-08-08 18:14:02 - \u001b[2;36m18:14:02-062681\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m If this operation ever runs too long, you can rerun    \n",
      "2023-08-08 18:14:02 - \u001b[2;36m18:14:02-065600\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Installing modules from requirements_linux.txt\u001b[33m...\u001b[0m      \n",
      "2023-08-08 18:14:02 - \u001b[2;36m18:14:02-063823\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Python \u001b[1;36m3.9\u001b[0m.\u001b[1;36m16\u001b[0m on Linux                                 \n",
      "2023-08-08 18:14:02 - \u001b[2;36m                \u001b[0m         this script in verbose mode to check.                  \n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m \u001b[2;33m/home/datascience/decompressed_artifact/code/job_artifact/kohya_ss/setup/\u001b[0m\u001b[1;33mset\u001b[0m \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m╭─\u001b[0m\u001b[30m────────────────────\u001b[0m\u001b[30m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[30m \u001b[0m\u001b[30m─────────────────────\u001b[0m\u001b[30m─╮\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m \u001b[1;33mup_linux.py\u001b[0m:\u001b[94m22\u001b[0m in \u001b[92mmain_menu\u001b[0m                                                  \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m \u001b[2;33m/home/datascience/decompressed_artifact/code/job_artifact/kohya_ss/setup/\u001b[0m\u001b[1;33mset\u001b[0m \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m   \u001b[2m38 \u001b[0m                                                                        \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m \u001b[31m❱ \u001b[0m37     main_menu(args.platform_requirements_file, show_stdout=args.show_st \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m   \u001b[2m36 \u001b[0m                                                                        \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m \u001b[1;33mup_linux.py\u001b[0m:\u001b[94m37\u001b[0m in \u001b[92m<module>\u001b[0m                                                   \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m \u001b[1;33mup_common.py\u001b[0m:\u001b[94m379\u001b[0m in \u001b[92minstall_requirements\u001b[0m                                     \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m \u001b[2;33m/home/datascience/decompressed_artifact/code/job_artifact/kohya_ss/setup/\u001b[0m\u001b[1;33mset\u001b[0m \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m   \u001b[2m23 \u001b[0m    \u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m no_run_accelerate:                                           \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m \u001b[31m❱ \u001b[0m22     setup_common.install_requirements(platform_requirements_file, check \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m   \u001b[2m21 \u001b[0m    setup_common.install(\u001b[33m'\u001b[0m\u001b[33m--upgrade pip\u001b[0m\u001b[33m'\u001b[0m)                               \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[1;91mFileNotFoundError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m No such file or directory: \u001b[32m'requirements_linux.txt'\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m   \u001b[2m380 \u001b[0m        \u001b[2m# Read lines from the requirements file, strip whitespace, and\u001b[0m \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m \u001b[31m❱ \u001b[0m379     \u001b[94mwith\u001b[0m \u001b[96mopen\u001b[0m(requirements_file, \u001b[33m'\u001b[0m\u001b[33mr\u001b[0m\u001b[33m'\u001b[0m, encoding=\u001b[33m'\u001b[0m\u001b[33mutf8\u001b[0m\u001b[33m'\u001b[0m) \u001b[94mas\u001b[0m f:           \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m   \u001b[2m378 \u001b[0m        log.info(\u001b[33mf\u001b[0m\u001b[33m'\u001b[0m\u001b[33mInstalling modules from \u001b[0m\u001b[33m{\u001b[0mrequirements_file\u001b[33m}\u001b[0m\u001b[33m...\u001b[0m\u001b[33m'\u001b[0m)    \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - \u001b[30m│\u001b[0m                                                                              \u001b[30m│\u001b[0m\n",
      "2023-08-08 18:14:02 - Please note if you'd like to expose your public server you need to run ./gui.sh --share\n",
      "2023-08-08 18:14:02 - Setup finished! Run \u001b[0;92m./gui.sh\u001b[0m to start.\n",
      "2023-08-08 18:14:02 - sh: kohya_ss/venv/bin/activate: No such file or directory\n",
      "2023-08-08 18:14:02 - Local folder for iamges is ./sks/img/1_sks\n",
      "2023-08-08 18:14:02 - ['West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_1 - Copy.jpg', 'West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_1.jpg', 'West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_2 - Copy.jpg', 'West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_2.jpg', 'West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_3 - Copy.jpg', 'West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_3.jpg', 'West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_4 - Copy.jpg', 'West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_4.jpg', 'West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_5 - Copy.jpg', 'West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_5.jpg']\n",
      "2023-08-08 18:14:02 - storing image West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_1 - Copy.jpg in ./sks/img/1_sks\n",
      "2023-08-08 18:14:02 - storing image West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_1.jpg in ./sks/img/1_sks\n",
      "2023-08-08 18:14:03 - storing image West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_2 - Copy.jpg in ./sks/img/1_sks\n",
      "2023-08-08 18:14:03 - storing image West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_2.jpg in ./sks/img/1_sks\n",
      "2023-08-08 18:14:03 - storing image West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_3 - Copy.jpg in ./sks/img/1_sks\n",
      "2023-08-08 18:14:03 - storing image West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_3.jpg in ./sks/img/1_sks\n",
      "2023-08-08 18:14:03 - storing image West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_4 - Copy.jpg in ./sks/img/1_sks\n",
      "2023-08-08 18:14:03 - storing image West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_4.jpg in ./sks/img/1_sks\n",
      "2023-08-08 18:14:03 - storing image West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_5 - Copy.jpg in ./sks/img/1_sks\n",
      "2023-08-08 18:14:03 - storing image West_BP@frqap2zhtzbe/stable_diffusion/input_folder/img_5.jpg in ./sks/img/1_sks\n",
      "2023-08-08 18:14:03 - ['./sks/img/1_sks']\n",
      "2023-08-08 18:14:03 - Profile images are stored locally at ./sks/img/1_sks\n",
      "2023-08-08 18:14:05 - [2023-08-08 18:14:05,087] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "2023-08-08 18:14:08 - \u001b[2;36m           \u001b[0m         `accelerate launch` and had defaults used      \u001b[2m             \u001b[0m\n",
      "2023-08-08 18:14:08 - \u001b[2;36m[18:14:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m The following values were not passed to        \u001b]8;id=28764;file:///home/datascience/conda/pytorch20_p39_gpu_v1/lib/python3.9/site-packages/accelerate/commands/launch.py\u001b\\\u001b[2mlaunch.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=97995;file:///home/datascience/conda/pytorch20_p39_gpu_v1/lib/python3.9/site-packages/accelerate/commands/launch.py#913\u001b\\\u001b[2m913\u001b[0m\u001b]8;;\u001b\\\n",
      "2023-08-08 18:14:08 - \u001b[2;36m           \u001b[0m                 `--dynamo_backend` was set to a value  \u001b[2m             \u001b[0m\n",
      "2023-08-08 18:14:08 - \u001b[2;36m           \u001b[0m         of `\u001b[32m'no'\u001b[0m`                                      \u001b[2m             \u001b[0m\n",
      "2023-08-08 18:14:08 - \u001b[2;36m           \u001b[0m                 `--mixed_precision` was set to a value \u001b[2m             \u001b[0m\n",
      "2023-08-08 18:14:08 - \u001b[2;36m           \u001b[0m         `\u001b[1;36m1\u001b[0m`                                            \u001b[2m             \u001b[0m\n",
      "2023-08-08 18:14:08 - \u001b[2;36m           \u001b[0m                 `--num_machines` was set to a value of \u001b[2m             \u001b[0m\n",
      "2023-08-08 18:14:08 - \u001b[2;36m           \u001b[0m         of `\u001b[1;36m1\u001b[0m`                                         \u001b[2m             \u001b[0m\n",
      "2023-08-08 18:14:08 - \u001b[2;36m           \u001b[0m                 `--num_processes` was set to a value   \u001b[2m             \u001b[0m\n",
      "2023-08-08 18:14:08 - \u001b[2;36m           \u001b[0m         instead:                                       \u001b[2m             \u001b[0m\n",
      "2023-08-08 18:14:08 - \u001b[2;36m           \u001b[0m         `accelerate config`.                           \u001b[2m             \u001b[0m\n",
      "2023-08-08 18:14:08 - \u001b[2;36m           \u001b[0m         of the problematic parameters or run           \u001b[2m             \u001b[0m\n",
      "2023-08-08 18:14:08 - \u001b[2;36m           \u001b[0m         To avoid this warning pass in values for each  \u001b[2m             \u001b[0m\n",
      "2023-08-08 18:14:08 - \u001b[2;36m           \u001b[0m         of `\u001b[32m'no'\u001b[0m`                                      \u001b[2m             \u001b[0m\n",
      "2023-08-08 18:14:10 - [2023-08-08 18:14:10,011] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "2023-08-08 18:14:14 - prepare tokenizers\n",
      "2023-08-08 18:14:17 - Using DreamBooth method.\n",
      "2023-08-08 18:14:17 - prepare images.\n",
      "2023-08-08 18:14:17 - sks/img/1_sks/img_2 - Copy.jpg\n",
      "2023-08-08 18:14:17 - sks/img/1_sks/img_1.jpg\n",
      "2023-08-08 18:14:17 - sks/img/1_sks/img_1 - Copy.jpg\n",
      "2023-08-08 18:14:17 - No caption file found for 10 images. Training will continue without captions for these images. If class token exists, it will be used. / 10枚の画像にキャプションファイルが見つかりませんでした。これらの画像についてはキャプションなしで学習を続行します。class tokenが存在する場合はそれを使います。\n",
      "2023-08-08 18:14:17 - found directory sks/img/1_sks contains 10 image files\n",
      "2023-08-08 18:14:17 -   resolution: (1024, 1024)\n",
      "2023-08-08 18:14:17 -   batch_size: 1\n",
      "2023-08-08 18:14:17 - [Dataset 0]\n",
      "2023-08-08 18:14:17 - no regularization images / 正則化画像が見つかりませんでした\n",
      "2023-08-08 18:14:17 - 0 reg images.\n",
      "2023-08-08 18:14:17 - 10 train images with repeating.\n",
      "2023-08-08 18:14:17 - sks/img/1_sks/img_3.jpg... and 5 more\n",
      "2023-08-08 18:14:17 - sks/img/1_sks/img_3 - Copy.jpg\n",
      "2023-08-08 18:14:17 - sks/img/1_sks/img_2.jpg\n",
      "2023-08-08 18:14:17 -   max_bucket_reso: 2048\n",
      "2023-08-08 18:14:17 -   min_bucket_reso: 256\n",
      "2023-08-08 18:14:17 -   enable_bucket: True\n",
      "2023-08-08 18:14:17 -   bucket_reso_steps: 64\n",
      "2023-08-08 18:14:17 -     caption_dropout_every_n_epoches: 0\n",
      "2023-08-08 18:14:17 -     caption_dropout_rate: 0.0\n",
      "2023-08-08 18:14:17 -     keep_tokens: 0\n",
      "2023-08-08 18:14:17 -     shuffle_caption: False\n",
      "2023-08-08 18:14:17 -     num_repeats: 1\n",
      "2023-08-08 18:14:17 -     image_count: 10\n",
      "2023-08-08 18:14:17 -     image_dir: \"sks/img/1_sks\"\n",
      "2023-08-08 18:14:17 -   [Subset 0 of Dataset 0]\n",
      "2023-08-08 18:14:17 - \n",
      "2023-08-08 18:14:17 -   bucket_no_upscale: True\n",
      "2023-08-08 18:14:17 -     is_reg: False\n",
      "2023-08-08 18:14:17 -     token_warmup_step: 0,\n",
      "2023-08-08 18:14:17 -     token_warmup_min: 1,\n",
      "2023-08-08 18:14:17 -     random_crop: False\n",
      "2023-08-08 18:14:17 -     face_crop_aug_range: None\n",
      "2023-08-08 18:14:17 -     flip_aug: False\n",
      "2023-08-08 18:14:17 -     color_aug: False\n",
      "2023-08-08 18:14:17 -     caption_tag_dropout_rate: 0.0\n",
      "2023-08-08 18:14:17 - loading image sizes.\n",
      "2023-08-08 18:14:17 - [Dataset 0]\n",
      "2023-08-08 18:14:17 - \n",
      "2023-08-08 18:14:17 - \n",
      "2023-08-08 18:14:17 -     caption_extension: .caption\n",
      "2023-08-08 18:14:17 -     class_tokens: sks\n",
      "2023-08-08 18:14:17 - load StableDiffusion checkpoint: stable-diffusion-xl-base-1.0/sd_xl_base_1.0.safetensors\n",
      "2023-08-08 18:14:17 - loading model for process 0/1\n",
      "2023-08-08 18:14:17 - preparing accelerator\n",
      "2023-08-08 18:14:17 - noise_offset is set to 0.0357 / noise_offsetが0.0357に設定されました\n",
      "2023-08-08 18:14:17 - mean ar error (without repeats): 0.0\n",
      "2023-08-08 18:14:17 - bucket 0: resolution (1024, 1024), count: 10\n",
      "2023-08-08 18:14:17 - number of images (including repeats) / 各bucketの画像枚数（繰り返し回数を含む）\n",
      "2023-08-08 18:14:17 - min_bucket_reso and max_bucket_reso are ignored if bucket_no_upscale is set, because bucket reso is defined by image size automatically / bucket_no_upscaleが指定された場合は、bucketの解像度は画像サイズから自動計算されるため、min_bucket_resoとmax_bucket_resoは無視されます\n",
      "2023-08-08 18:14:17 - make buckets\n",
      "2023-08-08 18:14:18 - building U-Net\n",
      "2023-08-08 18:14:19 - loading U-Net from checkpoint\n",
      "2023-08-08 18:14:21 - building text encoders\n",
      "2023-08-08 18:14:21 - U-Net:  <All keys matched successfully>\n",
      "2023-08-08 18:14:31 - loading text encoders from checkpoint\n",
      "2023-08-08 18:14:31 - text encoder 1: <All keys matched successfully>\n",
      "2023-08-08 18:14:31 - building VAE\n",
      "2023-08-08 18:14:31 - text encoder 2: <All keys matched successfully>\n",
      "2023-08-08 18:14:32 - loading VAE from checkpoint\n",
      "2023-08-08 18:14:32 - VAE: <All keys matched successfully>\n",
      "2023-08-08 18:14:32 - Enable xformers for U-Net\n",
      "2023-08-08 18:14:34 - import network module: networks.lora\n",
      "2023-08-08 18:14:34 - checking cache validity...\n",
      "2023-08-08 18:14:34 - caching latents.\n",
      "2023-08-08 18:14:34 - [Dataset 0]\n",
      "2023-08-08 18:14:34 - caching latents...\n",
      "2023-08-08 18:14:39 - create LoRA for Text Encoder 1:\n",
      "2023-08-08 18:14:39 - neuron dropout: p=None, rank dropout: p=None, module dropout: p=None\n",
      "2023-08-08 18:14:39 - create LoRA network. base dim (rank): 256, alpha: 1.0\n",
      "2023-08-08 18:14:40 - create LoRA for Text Encoder 2:\n",
      "2023-08-08 18:14:42 - create LoRA for Text Encoder: 264 modules.\n",
      "2023-08-08 18:14:49 - create LoRA for U-Net: 722 modules.\n",
      "2023-08-08 18:14:49 - enable LoRA for U-Net\n",
      "2023-08-08 18:14:49 - enable LoRA for text encoder\n",
      "2023-08-08 18:14:49 - prepare optimizer, data loader etc.\n",
      "2023-08-08 18:14:49 - use Adafactor optimizer | {'scale_parameter': False, 'relative_step': False, 'warmup_init': False}\n",
      "2023-08-08 18:14:49 - constant_with_warmup will be good / スケジューラはconstant_with_warmupが良いかもしれません\n",
      "2023-08-08 18:14:49 - because max_grad_norm is set, clip_grad_norm is enabled. consider set to 0 / max_grad_normが設定されているためclip_grad_normが有効になります。0に設定して無効にしたほうがいいかもしれません\n",
      "2023-08-08 18:14:51 -   num train images * repeats / 学習画像の数×繰り返し回数: 10\n",
      "2023-08-08 18:14:51 - running training / 学習開始\n",
      "2023-08-08 18:14:51 -   total optimization steps / 学習ステップ数: 1200\n",
      "2023-08-08 18:14:51 -   gradient accumulation steps / 勾配を合計するステップ数 = 1\n",
      "2023-08-08 18:14:51 -   batch size per device / バッチサイズ: 1\n",
      "2023-08-08 18:14:51 -   num epochs / epoch数: 120\n",
      "2023-08-08 18:14:51 -   num batches per epoch / 1epochのバッチ数: 10\n",
      "2023-08-08 18:14:51 -   num reg images / 正則化画像の数: 0\n",
      "2023-08-08 18:14:58 - epoch 1/120\n",
      "2023-08-08 18:14:58 - \n",
      "2023-08-08 18:14:07 - 2023-08-08 18:14:07.451912: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-08 18:14:07 - To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-08 18:14:07 - 2023-08-08 18:14:07.499946: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "2023-08-08 18:14:08 - 2023-08-08 18:14:08.220544: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-08 18:14:12 - 2023-08-08 18:14:12.165786: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-08 18:14:12 - To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-08 18:14:12 - 2023-08-08 18:14:12.213373: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "2023-08-08 18:14:12 - 2023-08-08 18:14:12.921784: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Downloading (…)olve/main/vocab.json: 100% 961k/961k [00:00<00:00, 10.3MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100% 525k/525k [00:00<00:00, 85.3MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100% 389/389 [00:00<00:00, 425kB/s]\n",
      "Downloading (…)okenizer_config.json: 100% 905/905 [00:00<00:00, 1.02MB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100% 862k/862k [00:00<00:00, 15.7MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100% 525k/525k [00:00<00:00, 1.91MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100% 389/389 [00:00<00:00, 457kB/s]\n",
      "Downloading (…)okenizer_config.json: 100% 904/904 [00:00<00:00, 1.19MB/s]\n",
      "100% 10/10 [00:00<00:00, 1689.21it/s]\n",
      "100% 10/10 [00:00<00:00, 80815.11it/s]\n",
      "100% 10/10 [00:04<00:00,  2.13it/s]\n",
      "2023-08-08 18:15:14 - epoch 2/120\n",
      "2023-08-08 18:15:14 - \n",
      "2023-08-08 18:15:30 - epoch 3/120\n",
      "2023-08-08 18:15:30 - \n",
      "2023-08-08 18:15:47 - epoch 4/120\n",
      "2023-08-08 18:15:47 - \n",
      "2023-08-08 18:16:03 - epoch 5/120\n",
      "2023-08-08 18:16:03 - \n",
      "2023-08-08 18:16:52 - epoch 8/120\n",
      "2023-08-08 18:16:52 - \n",
      "2023-08-08 18:17:09 - epoch 9/120\n",
      "2023-08-08 18:17:09 - \n",
      "2023-08-08 18:16:19 - \n",
      "2023-08-08 18:16:19 - epoch 6/120\n",
      "2023-08-08 18:16:36 - epoch 7/120\n",
      "2023-08-08 18:16:36 - \n",
      "2023-08-08 18:17:25 - epoch 10/120\n",
      "2023-08-08 18:17:25 - \n",
      "2023-08-08 18:17:42 - epoch 11/120\n",
      "2023-08-08 18:17:42 - \n",
      "2023-08-08 18:18:32 - epoch 14/120\n",
      "2023-08-08 18:18:32 - \n",
      "2023-08-08 18:18:48 - epoch 15/120\n",
      "2023-08-08 18:18:48 - \n",
      "2023-08-08 18:19:05 - epoch 16/120\n",
      "2023-08-08 18:19:05 - \n",
      "2023-08-08 18:19:21 - epoch 17/120\n",
      "2023-08-08 18:19:21 - \n",
      "2023-08-08 18:17:58 - epoch 12/120\n",
      "2023-08-08 18:17:58 - \n",
      "2023-08-08 18:18:15 - epoch 13/120\n",
      "2023-08-08 18:18:15 - \n",
      "2023-08-08 18:19:38 - epoch 18/120\n",
      "2023-08-08 18:19:38 - \n",
      "2023-08-08 18:19:54 - epoch 19/120\n",
      "2023-08-08 18:19:54 - \n",
      "2023-08-08 18:20:11 - epoch 20/120\n",
      "2023-08-08 18:20:11 - \n",
      "2023-08-08 18:20:28 - \n",
      "2023-08-08 18:20:28 - epoch 21/120\n",
      "2023-08-08 18:20:44 - epoch 22/120\n",
      "2023-08-08 18:20:44 - \n",
      "2023-08-08 18:21:01 - epoch 23/120\n",
      "2023-08-08 18:21:01 - \n",
      "2023-08-08 18:21:18 - epoch 24/120\n",
      "2023-08-08 18:21:18 - \n",
      "2023-08-08 18:21:34 - epoch 25/120\n",
      "2023-08-08 18:21:34 - \n",
      "2023-08-08 18:22:24 - epoch 28/120\n",
      "2023-08-08 18:22:24 - \n",
      "2023-08-08 18:22:41 - epoch 29/120\n",
      "2023-08-08 18:22:41 - \n",
      "2023-08-08 18:21:51 - epoch 26/120\n",
      "2023-08-08 18:21:51 - \n",
      "2023-08-08 18:22:07 - epoch 27/120\n",
      "2023-08-08 18:22:07 - \n",
      "2023-08-08 18:22:57 - \n",
      "2023-08-08 18:22:57 - epoch 30/120\n",
      "2023-08-08 18:23:14 - epoch 31/120\n",
      "2023-08-08 18:23:14 - \n",
      "2023-08-08 18:23:31 - epoch 32/120\n",
      "2023-08-08 18:23:31 - \n",
      "2023-08-08 18:23:47 - epoch 33/120\n",
      "2023-08-08 18:23:47 - \n",
      "2023-08-08 18:24:04 - epoch 34/120\n",
      "2023-08-08 18:24:04 - \n",
      "2023-08-08 18:24:21 - epoch 35/120\n",
      "2023-08-08 18:24:21 - \n",
      "2023-08-08 18:24:38 - epoch 36/120\n",
      "2023-08-08 18:24:38 - \n",
      "2023-08-08 18:24:54 - epoch 37/120\n",
      "2023-08-08 18:24:54 - \n",
      "2023-08-08 18:25:11 - \n",
      "2023-08-08 18:25:11 - epoch 38/120\n",
      "2023-08-08 18:25:28 - epoch 39/120\n",
      "2023-08-08 18:25:28 - \n",
      "2023-08-08 18:25:44 - epoch 40/120\n",
      "2023-08-08 18:25:44 - \n",
      "2023-08-08 18:26:01 - epoch 41/120\n",
      "2023-08-08 18:26:01 - \n",
      "2023-08-08 18:26:51 - epoch 44/120\n",
      "2023-08-08 18:26:51 - \n",
      "2023-08-08 18:27:08 - \n",
      "2023-08-08 18:27:08 - epoch 45/120\n",
      "2023-08-08 18:26:18 - epoch 42/120\n",
      "2023-08-08 18:26:18 - \n",
      "2023-08-08 18:26:34 - epoch 43/120\n",
      "2023-08-08 18:26:34 - \n",
      "2023-08-08 18:27:24 - epoch 46/120\n",
      "2023-08-08 18:27:24 - \n",
      "2023-08-08 18:27:41 - epoch 47/120\n",
      "2023-08-08 18:27:41 - \n",
      "2023-08-08 18:27:57 - \n",
      "2023-08-08 18:27:57 - epoch 48/120\n",
      "2023-08-08 18:28:14 - epoch 49/120\n",
      "2023-08-08 18:28:14 - \n",
      "2023-08-08 18:28:31 - epoch 50/120\n",
      "2023-08-08 18:28:31 - \n",
      "2023-08-08 18:28:48 - epoch 51/120\n",
      "2023-08-08 18:28:48 - \n",
      "2023-08-08 18:29:04 - \n",
      "2023-08-08 18:29:04 - epoch 52/120\n",
      "2023-08-08 18:29:21 - epoch 53/120\n",
      "2023-08-08 18:29:21 - \n",
      "2023-08-08 18:30:44 - epoch 58/120\n",
      "2023-08-08 18:30:44 - \n",
      "2023-08-08 18:31:01 - epoch 59/120\n",
      "2023-08-08 18:31:01 - \n",
      "2023-08-08 18:29:38 - epoch 54/120\n",
      "2023-08-08 18:29:38 - \n",
      "2023-08-08 18:29:54 - epoch 55/120\n",
      "2023-08-08 18:29:54 - \n",
      "2023-08-08 18:30:11 - epoch 56/120\n",
      "2023-08-08 18:30:11 - \n",
      "2023-08-08 18:30:27 - epoch 57/120\n",
      "2023-08-08 18:30:27 - \n",
      "2023-08-08 18:31:17 - epoch 60/120\n",
      "2023-08-08 18:31:17 - \n",
      "2023-08-08 18:31:34 - epoch 61/120\n",
      "2023-08-08 18:31:34 - \n",
      "2023-08-08 18:31:51 - epoch 62/120\n",
      "2023-08-08 18:31:51 - \n",
      "2023-08-08 18:32:07 - epoch 63/120\n",
      "2023-08-08 18:32:07 - \n",
      "2023-08-08 18:32:24 - epoch 64/120\n",
      "2023-08-08 18:32:24 - \n",
      "2023-08-08 18:32:40 - epoch 65/120\n",
      "2023-08-08 18:32:40 - \n",
      "2023-08-08 18:32:57 - epoch 66/120\n",
      "2023-08-08 18:32:57 - \n",
      "2023-08-08 18:33:13 - epoch 67/120\n",
      "2023-08-08 18:33:13 - \n",
      "2023-08-08 18:33:30 - epoch 68/120\n",
      "2023-08-08 18:33:30 - \n",
      "2023-08-08 18:33:47 - epoch 69/120\n",
      "2023-08-08 18:33:47 - \n",
      "2023-08-08 18:34:37 - \n",
      "2023-08-08 18:34:37 - epoch 72/120\n",
      "2023-08-08 18:34:53 - \n",
      "2023-08-08 18:34:53 - epoch 73/120\n",
      "2023-08-08 18:34:03 - \n",
      "2023-08-08 18:34:03 - epoch 70/120\n",
      "2023-08-08 18:34:20 - epoch 71/120\n",
      "2023-08-08 18:34:20 - \n",
      "2023-08-08 18:35:10 - epoch 74/120\n",
      "2023-08-08 18:35:10 - \n",
      "2023-08-08 18:35:27 - epoch 75/120\n",
      "2023-08-08 18:35:27 - \n",
      "2023-08-08 18:35:43 - epoch 76/120\n",
      "2023-08-08 18:35:43 - \n",
      "2023-08-08 18:36:00 - epoch 77/120\n",
      "2023-08-08 18:36:00 - \n",
      "2023-08-08 18:36:16 - \n",
      "2023-08-08 18:36:16 - epoch 78/120\n",
      "2023-08-08 18:36:33 - epoch 79/120\n",
      "2023-08-08 18:36:33 - \n",
      "2023-08-08 18:36:50 - epoch 80/120\n",
      "2023-08-08 18:36:50 - \n",
      "2023-08-08 18:37:06 - \n",
      "2023-08-08 18:37:06 - epoch 81/120\n",
      "2023-08-08 18:37:23 - epoch 82/120\n",
      "2023-08-08 18:37:23 - \n",
      "2023-08-08 18:37:40 - epoch 83/120\n",
      "2023-08-08 18:37:40 - \n",
      "2023-08-08 18:37:56 - epoch 84/120\n",
      "2023-08-08 18:37:56 - \n",
      "2023-08-08 18:38:13 - epoch 85/120\n",
      "2023-08-08 18:38:13 - \n",
      "2023-08-08 18:39:03 - epoch 88/120\n",
      "2023-08-08 18:39:03 - \n",
      "2023-08-08 18:39:20 - epoch 89/120\n",
      "2023-08-08 18:39:20 - \n",
      "2023-08-08 18:38:30 - epoch 86/120\n",
      "2023-08-08 18:38:30 - \n",
      "2023-08-08 18:38:46 - \n",
      "2023-08-08 18:38:46 - epoch 87/120\n",
      "2023-08-08 18:39:36 - \n",
      "2023-08-08 18:39:36 - epoch 90/120\n",
      "2023-08-08 18:39:53 - epoch 91/120\n",
      "2023-08-08 18:39:53 - \n",
      "2023-08-08 18:40:10 - epoch 92/120\n",
      "2023-08-08 18:40:10 - \n",
      "2023-08-08 18:40:26 - epoch 93/120\n",
      "2023-08-08 18:40:26 - \n",
      "2023-08-08 18:40:43 - epoch 94/120\n",
      "2023-08-08 18:40:43 - \n",
      "2023-08-08 18:41:00 - epoch 95/120\n",
      "2023-08-08 18:41:00 - \n",
      "2023-08-08 18:41:16 - \n",
      "2023-08-08 18:41:16 - epoch 96/120\n",
      "2023-08-08 18:41:33 - epoch 97/120\n",
      "2023-08-08 18:41:33 - \n",
      "2023-08-08 18:42:23 - epoch 100/120\n",
      "2023-08-08 18:42:23 - \n",
      "2023-08-08 18:42:40 - epoch 101/120\n",
      "2023-08-08 18:42:40 - \n",
      "2023-08-08 18:41:50 - epoch 98/120\n",
      "2023-08-08 18:41:50 - \n",
      "2023-08-08 18:42:06 - \n",
      "2023-08-08 18:42:06 - epoch 99/120\n",
      "2023-08-08 18:42:56 - epoch 102/120\n",
      "2023-08-08 18:42:56 - \n",
      "2023-08-08 18:43:13 - epoch 103/120\n",
      "2023-08-08 18:43:13 - \n",
      "2023-08-08 18:43:29 - epoch 104/120\n",
      "2023-08-08 18:43:29 - \n",
      "2023-08-08 18:43:46 - epoch 105/120\n",
      "2023-08-08 18:43:46 - \n",
      "2023-08-08 18:44:03 - epoch 106/120\n",
      "2023-08-08 18:44:03 - \n",
      "2023-08-08 18:44:19 - epoch 107/120\n",
      "2023-08-08 18:44:19 - \n",
      "2023-08-08 18:44:36 - \n",
      "2023-08-08 18:44:36 - epoch 108/120\n",
      "2023-08-08 18:44:52 - epoch 109/120\n",
      "2023-08-08 18:44:52 - \n",
      "2023-08-08 18:45:09 - epoch 110/120\n",
      "2023-08-08 18:45:09 - \n",
      "2023-08-08 18:45:26 - epoch 111/120\n",
      "2023-08-08 18:45:26 - \n",
      "2023-08-08 18:45:42 - epoch 112/120\n",
      "2023-08-08 18:45:42 - \n",
      "2023-08-08 18:45:59 - epoch 113/120\n",
      "2023-08-08 18:45:59 - \n",
      "2023-08-08 18:46:48 - epoch 116/120\n",
      "2023-08-08 18:46:48 - \n",
      "2023-08-08 18:47:05 - epoch 117/120\n",
      "2023-08-08 18:47:05 - \n",
      "2023-08-08 18:46:15 - epoch 114/120\n",
      "2023-08-08 18:46:15 - \n",
      "2023-08-08 18:46:32 - epoch 115/120\n",
      "2023-08-08 18:46:32 - \n",
      "2023-08-08 18:47:21 - epoch 118/120\n",
      "2023-08-08 18:47:21 - \n",
      "2023-08-08 18:47:38 - epoch 119/120\n",
      "2023-08-08 18:47:38 - \n",
      "2023-08-08 18:49:11 - Done!\n",
      "2023-08-08 18:47:55 - epoch 120/120\n",
      "2023-08-08 18:47:55 - \n",
      "2023-08-08 18:48:11 - saving checkpoint: sks/output/sks.safetensors\n",
      "2023-08-08 18:48:11 - \n",
      "2023-08-08 18:48:17 - model saved.\n",
      "steps:  19% 228/1... [06:14<26:47,  1.65s/it, loss=0.0601]\n",
      "steps:  31% 368/1200...0:08<23:00,  1.66s/it, loss=0.176] \n",
      "steps:  66% .../1200 [21:50<11:22,  1.66s/it, loss=0.088] 1.66s/it, loss=0.153]\n",
      "steps:  54% 64...200 [17:56<15:16,  1.66s/it, loss=0.143] \n",
      "steps:  42% 508...00 [14:03<19:08,  1.66s/it, loss=0.128] \n",
      "steps: 100% 1200/1200 [33:19<00:00,  1.67s/it, loss=0.126] \n",
      "steps:  89% 1068/1200 [29:34<03:39,  1.66s/it, loss=...48] it, loss=0.0581]\n",
      "steps: ...% 929/1200 [25:43<07:30,  1.66s/it, loss=0.0885]\n",
      "2023-08-08 18:48:19 - ----------------------- Training done\n",
      "2023-08-08 18:48:21 - [2023-08-08 18:48:21,066] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "2023-08-08 18:48:26 - building U-Net\n",
      "2023-08-08 18:48:27 - loading U-Net from checkpoint\n",
      "2023-08-08 18:48:27 - building text encoders\n",
      "2023-08-08 18:48:27 - U-Net:  <All keys matched successfully>\n",
      "2023-08-08 18:48:37 - loading text encoders from checkpoint\n",
      "2023-08-08 18:48:37 - text encoder 1: <All keys matched successfully>\n",
      "2023-08-08 18:48:37 - building VAE\n",
      "2023-08-08 18:48:37 - text encoder 2: <All keys matched successfully>\n",
      "2023-08-08 18:48:38 - loading VAE from checkpoint\n",
      "2023-08-08 18:48:38 - VAE: <All keys matched successfully>\n",
      "2023-08-08 18:48:40 - use float32 for vae\n",
      "2023-08-08 18:48:42 - create LoRA for Text Encoder 1:\n",
      "2023-08-08 18:48:42 - create LoRA network from weights\n",
      "2023-08-08 18:48:42 - create LoRA for Text Encoder 2:\n",
      "2023-08-08 18:48:44 - create LoRA for Text Encoder: 264 modules.\n",
      "2023-08-08 18:48:52 - enable LoRA for text encoder\n",
      "2023-08-08 18:48:52 - create LoRA for U-Net: 722 modules.\n",
      "2023-08-08 18:48:52 - enable LoRA for U-Net\n",
      "2023-08-08 18:48:54 - weights are merged\n",
      "ste...   7% 87/1200 [02:22<30:24,  1.64s/it, loss=0.15]  \n",
      "2023-08-08 18:48:23 - 2023-08-08 18:48:23.111793: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-08 18:48:23 - 2023-08-08 18:48:23.160073: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "2023-08-08 18:48:23 - To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-08 18:48:23 - 2023-08-08 18:48:23.865743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "100% 50/50 [00:15<00:00,  3.18it/s]\n",
      "2023-08-08 18:49:27 - Job Run SUCCEEDED, Job run artifact execution in progress.\n"
     ]
    }
   ],
   "source": [
    "job_run_env = job.run(\n",
    "    name=\"Job Run - Passing dynamic values\",\n",
    "    env_var={'full_input_folder': 'oci://West_BP@frqap2zhtzbe/stable_diffusion/input_folder/'}\n",
    ")\n",
    "\n",
    "job_run_watch = job_run_env.watch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - Exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/datascience/conda/pytorch20_p39_gpu_v1/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_20977/3105197982.py\", line 24, in <cell line: 17>\n",
      "    faces_rgb = face_cropper.get_faces(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB))\n",
      "  File \"/home/datascience/job_artifact/sub_packages/face_cropper.py\", line 576, in get_faces\n",
      "    inflated_face_image, face_landmarks = _get_roll_corrected_image_and_landmarks(inflated_face_image, face_landmarks)\n",
      "  File \"/home/datascience/job_artifact/sub_packages/face_cropper.py\", line 440, in _get_roll_corrected_image_and_landmarks\n",
      "    eyes_midpoint = _get_eyes_midpoint(left_eye_centre, right_eye_centre, face_image.shape)\n",
      "  File \"/home/datascience/job_artifact/sub_packages/face_cropper.py\", line 377, in _get_eyes_midpoint\n",
      "    (left_eye_centre[1] + right_eye_centre[1]) * image_size[0] / 2])), np.int)\n",
      "  File \"/home/datascience/conda/pytorch20_p39_gpu_v1/lib/python3.9/site-packages/numpy/__init__.py\", line 305, in __getattr__\n",
      "    raise AttributeError(__former_attrs__[attr])\n",
      "AttributeError: module 'numpy' has no attribute 'int'.\n",
      "`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img_1.jpg', 'img_5.jpg', 'img_2 - Copy.jpg', 'testout', 'img_5 - Copy.jpg', 'img_2.jpg', 'img_3.jpg', 'img_3 - Copy.jpg', '.ipynb_checkpoints', 'img_1 - Copy.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AttributeError: module 'numpy' has no attribute 'int'.\n",
      "`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "import secrets\n",
    "import os\n",
    "\n",
    "\n",
    "from job_artifact.sub_packages.face_cropper import FaceCropper\n",
    "#from sub_packages.face_cropper import FaceCropper\n",
    "\n",
    "#list of local images\n",
    "list_of_local_images = os.listdir(\"testimages\")\n",
    "print(list_of_local_images)\n",
    "count = 1\n",
    "\n",
    "#crop each image to face only and resize image\n",
    "for local_images in list_of_local_images:\n",
    "    \n",
    "    if local_images.endswith(\".jpg\"):\n",
    "\n",
    "        #crop image to face only\n",
    "        face_cropper = FaceCropper()\n",
    "        image_bgr = cv2.imread((\"./testimages/\" + local_images))\n",
    "        faces_rgb = face_cropper.get_faces(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB))\n",
    "        img_name = \"./testimages/testout/img_\"+str(count)\n",
    "\n",
    "        if not faces_rgb:\n",
    "            print(\"No faces detected\")\n",
    "        else:\n",
    "            #resize the image\n",
    "            dim = (1024, 1024)\n",
    "            resized_image = cv2.resize(faces_rgb, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "            print('Resized Dimensions of input image for training : ',resized_image.shape)\n",
    "\n",
    "            #save image\n",
    "            cv2.imwrite(img_name, resized_image)\n",
    "            count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Gradio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch20_p39_gpu_v1]",
   "language": "python",
   "name": "conda-env-pytorch20_p39_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "06b89612a5e9c675d881f7c391886fce9eabd2126328a7f9c136f634c360fd8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
